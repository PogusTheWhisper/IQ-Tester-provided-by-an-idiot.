from openai import OpenAI
import gradio as gr
import threading
import pygame

# OpenAI client setup
client = OpenAI(
    api_key="<Typhoon Key>",
    base_url="https://api.opentyphoon.ai/v1",
)

# Function to generate humorous IQ questions
def generate_questions():
    stream = client.chat.completions.create(
        model="typhoon-v1.5-instruct",
        messages=[
            {
                "role": "user",
                "content": """
                ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ AI ‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞‡∏™‡∏≤‡∏¢‡∏Ç‡∏≥‡∏Ç‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° IQ ‡πÅ‡∏ö‡∏ö‡∏Æ‡∏≤‡πÜ ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏û‡∏µ‡∏¢‡∏á 1 ‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡πá‡∏°‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢‡∏à‡∏¥‡∏ô‡∏ï‡∏ô‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏£‡∏Å‡∏∞‡∏Ç‡∏≥‡∏Ç‡∏±‡∏ô ‡πÇ‡∏î‡∏¢‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÄ‡∏•‡πà‡∏ô‡∏´‡∏±‡∏ß‡πÄ‡∏£‡∏≤‡∏∞‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏¥‡∏î‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå

                ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:
                - ‡πÉ‡∏ä‡πâ‡πÇ‡∏ó‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏ö‡∏≤‡∏™‡∏°‡∏≠‡∏á ‡∏™‡∏ô‡∏∏‡∏Å ‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏∞‡∏ï‡∏∏‡πâ‡∏ô‡∏à‡∏¥‡∏ô‡∏ï‡∏ô‡∏≤‡∏Å‡∏≤‡∏£
                - ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏ß‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡∏´‡∏•‡∏≤‡∏î‡πÉ‡∏à‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î
                - ‡πÄ‡∏ô‡πâ‡∏ô‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏Å‡∏°‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö

                ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:
                - ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡πâ‡∏≠‡∏ô‡∏ä‡∏µ‡∏™‡∏ó‡∏µ‡πà‡∏Å‡∏•‡∏±‡∏ß‡πÇ‡∏î‡∏ô‡∏Ç‡∏π‡∏î ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏ó‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏£‡∏≠‡∏î‡∏û‡πâ‡∏ô‡∏à‡∏≤‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏π‡∏î‡∏ä‡∏µ‡∏™?
                - ‡∏ñ‡πâ‡∏≤‡∏Å‡∏≤‡πÅ‡∏ü‡πÅ‡∏Å‡πâ‡∏ß‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ù‡∏±‡∏ô ‡∏≠‡∏¢‡∏≤‡∏Å‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏∞‡πÑ‡∏£‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡πÅ‡∏ü?
                - ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå‡∏ï‡πà‡∏≤‡∏á‡∏î‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏ñ‡∏∂‡∏á‡πÇ‡∏•‡∏Å‡πÅ‡∏•‡πâ‡∏ß‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ä‡∏ü‡∏ß‡πà‡∏≤‡∏≠‡∏∞‡πÑ‡∏£?

                ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á 1 ‡∏Ç‡πâ‡∏≠ ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÄ‡∏•‡πà‡∏ô‡∏´‡∏±‡∏ß‡πÄ‡∏£‡∏≤‡∏∞‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏¥‡∏î‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏≤‡∏î‡πÑ‡∏°‡πà‡∏ñ‡∏∂‡∏á!
                """,
            },
        ],
        max_tokens=512,
        temperature=0.8,
        top_p=0.95,
        stream=True,
    )

    respond = []
    for chunk in stream:
        if hasattr(chunk, 'choices') and len(chunk.choices) > 0:
            choice = chunk.choices[0]
            if hasattr(choice, 'delta') and hasattr(choice.delta, 'content'):
                if choice.delta.content is not None:
                    respond.append(choice.delta.content)
    return ''.join(respond)

# Function to provide humorous, creative answers to questions
def get_correct_answers(question):
    stream = client.chat.completions.create(
        model="typhoon-v1.5-instruct",
        messages=[
            {
                "role": "system",
                "content": """
                ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ AI ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° IQ ‡πÅ‡∏ö‡∏ö‡∏Ç‡∏≥‡πÜ ‡∏ó‡∏µ‡πà‡πÄ‡∏ô‡πâ‡∏ô‡∏à‡∏¥‡∏ô‡∏ï‡∏ô‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ô‡∏∏‡∏Å
                ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:
                - ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏£‡∏°‡∏µ‡∏ï‡∏£‡∏£‡∏Å‡∏∞‡∏ó‡∏µ‡πà‡πÄ‡∏ö‡∏≤‡∏™‡∏°‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏™‡∏ô‡∏∏‡∏Å‡∏™‡∏ô‡∏≤‡∏ô
                - ‡∏Ñ‡∏ß‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏´‡∏±‡∏ß‡πÄ‡∏£‡∏≤‡∏∞‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡∏´‡∏•‡∏≤‡∏î‡πÉ‡∏à‡πÉ‡∏´‡πâ‡∏Å‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏•‡πà‡∏ô
                - ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå ‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∏‡∏Ç

                ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:
                - ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡πâ‡∏≠‡∏ô‡∏ä‡∏µ‡∏™‡∏ó‡∏µ‡πà‡∏Å‡∏•‡∏±‡∏ß‡πÇ‡∏î‡∏ô‡∏Ç‡∏π‡∏î ‡∏Ñ‡∏∏‡∏ì‡∏à‡∏∞‡∏ó‡∏≥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏£‡∏≠‡∏î‡∏û‡πâ‡∏ô‡∏à‡∏≤‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏π‡∏î‡∏ä‡∏µ‡∏™?
                  ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: ‡πÅ‡∏Å‡∏•‡πâ‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ô‡∏°‡∏™‡∏î ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÉ‡∏´‡∏°‡πà!
                - ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: ‡∏ñ‡πâ‡∏≤‡∏Å‡∏≤‡πÅ‡∏ü‡πÅ‡∏Å‡πâ‡∏ß‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ù‡∏±‡∏ô ‡∏≠‡∏¢‡∏≤‡∏Å‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏∞‡πÑ‡∏£‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡πÅ‡∏ü?
                  ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö: ‡∏≠‡∏¢‡∏≤‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏∞‡πÄ‡∏• ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏ô‡πÄ‡∏ï‡∏¥‡∏°‡∏ô‡πâ‡∏≥‡πÉ‡∏à‡πÅ‡∏ó‡∏ô‡∏Ñ‡∏£‡∏µ‡∏°
                """
            },
            {
                "role": "user",
                "content": f"‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}",
            }
        ],
        max_tokens=512,
        temperature=0.8,
        top_p=0.9,
        stream=True,
    )

    respond = []
    for chunk in stream:
        if hasattr(chunk, 'choices') and len(chunk.choices) > 0:
            choice = chunk.choices[0]
            if hasattr(choice, 'delta') and hasattr(choice.delta, 'content'):
                if choice.delta.content is not None:
                    respond.append(choice.delta.content)
    return ''.join(respond)

# Function to evaluate the user's answers humorously
def evaluate_user(question, user_answer):
    stream = client.chat.completions.create(
        model="typhoon-v1.5-instruct",
        messages=[
            {
                "role": "system",
                "content": """
                ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ AI ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÄ‡∏•‡πà‡∏ô‡∏à‡∏≤‡∏Å‡πÅ‡∏ö‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö IQ ‡∏Ç‡∏≥‡πÜ ‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏°‡∏≤ ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÅ‡∏ö‡∏ö‡∏Ç‡∏≥‡πÜ ‡πÄ‡∏ä‡πà‡∏ô:
                - '‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ IQ 123 ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö‡∏Ç‡∏ô‡∏°‡∏õ‡∏±‡∏á‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ö‡∏ó‡∏Å‡∏ß‡∏µ ‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞ ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î!'
                - '‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ IQ 99 ‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ö‡πÅ‡∏°‡∏ß‡∏ô‡∏≠‡∏ô‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡πÅ‡∏î‡∏î‡∏à‡∏±‡∏î ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ú‡∏à‡∏ç‡∏†‡∏±‡∏¢‡πÉ‡∏ô‡πÇ‡∏•‡∏Å‡∏Ç‡∏≥‡∏Ç‡∏±‡∏ô!'
                """
            },
            {
                "role": "user",
                "content": f"‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}\n‡∏ú‡∏π‡πâ‡πÄ‡∏•‡πà‡∏ô‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ: {user_answer}",
            }
        ],
        max_tokens=512,
        temperature=0.7,
        top_p=0.9,
        stream=True,
    )

    respond = []
    for chunk in stream:
        if hasattr(chunk, 'choices') and len(chunk.choices) > 0:
            choice = chunk.choices[0]
            if hasattr(choice, 'delta') and hasattr(choice.delta, 'content'):
                if choice.delta.content is not None:
                    respond.append(choice.delta.content)
    return ''.join(respond)

def play_funny_sound():
    def play_sound():
        pygame.mixer.init()
        pygame.mixer.music.load("WOW.mp3")
        pygame.mixer.music.play()
        while pygame.mixer.music.get_busy():
            pygame.time.Clock().tick(10)

    threading.Thread(target=play_sound, daemon=True).start()
    
# Gradio UI setup
def interactive_flow():
    question = generate_questions()
    return question

def handle_submission(question, user_answer):
    evaluation = evaluate_user(question, user_answer)
    play_funny_sound()
    correct_answer = get_correct_answers(question)
    return evaluation, correct_answer

with gr.Blocks() as demo:
    gr.Markdown("# üß† ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ß‡∏±‡∏î‡πÑ‡∏≠‡∏Ñ‡∏¥‡∏ß‡∏Å‡∏±‡∏ö AI ‡∏£‡∏∞‡∏î‡∏±‡∏ö ü¶æsKyNeTü§ñ")
    question_display = gr.Textbox(label="‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° IQ ‡πÅ‡∏ö‡∏ö‡∏Æ‡∏≤‡πÜ", interactive=False)
    answer_input = gr.Textbox(label="‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì", placeholder="‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà...")
    submit_button = gr.Button("‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö")
    evaluation_output = gr.Textbox(label="‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå IQ ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì", interactive=False)
    correct_answer_output = gr.Textbox(label="‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å AI", interactive=False)

    submit_button.click(
        handle_submission,
        inputs=[question_display, answer_input],
        outputs=[evaluation_output, correct_answer_output],
    )

    demo.load(interactive_flow, outputs=[question_display])

demo.launch(share=True)
